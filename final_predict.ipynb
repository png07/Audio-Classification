{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f264a8c-9497-48f4-bff6-efb496f8da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d1aa22-be02-44f5-8351-c0a24874fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\pratik\\Documents\\Projects\\audio_classification\\savedmodels\\final_model90.keras'  # Path to your saved Keras model\n",
    "labelencoder_path = r'C:\\Users\\pratik\\Documents\\Projects\\audio_classification\\savedmodels\\label_encoder90.pkl'  # Path to your saved LabelEncoder\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "with open(labelencoder_path, 'rb') as file:\n",
    "    labelencoder = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a533ca6-aa10-4df8-8c67-0f3e284d20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_audio_label(filepath):\n",
    "    # Load the audio file\n",
    "    audio, sample_rate = librosa.load(filepath, res_type='kaiser_fast')\n",
    "\n",
    "    # Extract MFCC features\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "\n",
    "    # Reshape for Conv1D model\n",
    "    mfccs_scaled_features = mfccs_scaled_features.reshape(1, 40, 1)  # Adding the channel dimension\n",
    "\n",
    "    # Predict using the trained Conv1D model\n",
    "    y_pred = model.predict(mfccs_scaled_features)\n",
    "\n",
    "    # Get the predicted class\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # Decode the predicted class label\n",
    "    prediction_class = labelencoder.inverse_transform(y_pred_classes)\n",
    "\n",
    "    return prediction_class[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a7aaa0-06b5-4c65-b2b3-e50c620abb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "Predicted Label: car_horn\n"
     ]
    }
   ],
   "source": [
    "filepath = r\"C:\\Users\\pratik\\Documents\\Projects\\audio_classification\\UrbanSound8K\\audio\\fold9\\138468-1-0-0.wav\"\n",
    "predicted_label = predict_audio_label(filepath)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae169781-4067-483f-ae4e-597b460b5b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
